\documentclass[12pt]{article}
\usepackage{geometry}
\geometry{verbose,a4paper,tmargin=20mm,bmargin=30mm,lmargin=25mm,rmargin=25mm}

\usepackage{color}
\usepackage{authblk}
\usepackage{graphicx,hyperref}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{subeqnarray}
\usepackage{multirow}
\usepackage{marvosym}
\usepackage{natbib}
\usepackage{fancyheadings}
\usepackage{bm}

\usepackage{algorithm} 
\usepackage{algpseudocode}

 \setcounter{MaxMatrixCols}{20}
 
%\setcounter{Maxaffil}{0}
%\renewcommand\Affilfont{\itshape\small}

%% MATH
\newcommand{\real}{\mbox{\rm I$\!$R}}
\newcommand{\ese}{\mbox{\rm $\!$S}}
\newcommand{\toro}{\bf \mathbb{T}}
\newcommand{\defeq}{\triangleq}
\newcommand{\proofend}{ \hfill $\blacksquare$ \\}
\newcommand{\dif}[2]{\frac{d#1}{d#2}}
\newcommand{\dpar}[2]{\cfrac{\partial#1}{\partial#2}}
\newcommand{\ddpar}[3]{\frac{\partial^2#1}{\partial#2\partial#3}}

%%%%%%%%%%%%%%%%%%%%%
%
%      paper title
%
%%%%%%%%%%%%%%%%%%%%%
\title{A brief introduction to nocs}
%
\author{Daniel Cardona-Ortiz}
\affil{Robotics and Advanced Manufacturing Group, Cinvestav, Mexico}
%\date{}

\begin{document}
\maketitle

This document presents the theoretical background of the algorithms implemented in the local collocation module of nocs (Numerical optimal control solver). The author suggest to verify (Betts) and (ICRA) for total understanding of the Gauss-Lobatto methods applied in this solver.

\section{Optimal control problem for robotic systems}

given an articulated rigid body system with $n$ degrees of freedom (DoF) and a state vector
%
\begin{equation}
\label{eq:state}
\bm{x}= \begin{bmatrix}\bm{q}
\\ \dot{\bm{q}}
\end{bmatrix} \in \real^{2n}, 
\end{equation}
%
where $\{\bm{q},\dot{\bm{q}}\} \in \real^{n}$ are the robot configuration, and joint velocities, respectively, find a control law (if exists) that leads the system from its initial state to a final one by solving:
%
\begin{equation} \label{eq:1}
\begin{aligned}
&\underset{\bm{u}(t) \in \bm{U}}{\text{min}} 
& & \phi(\bm{x}(0),\bm{x}(T),t_0,t_F)+\int_{0}^{T} \L(\bm{x}(t),\bm{u}(t),t) dt
\end{aligned}
\end{equation}
%
\begin{equation} \label{eq:2}
\begin{aligned}
& \text{subject to} & & \dot{\bm{x}}(t)=\bm{f}(\bm{x}(t),\bm{u}(t),t)\\
& & & \bm{h}(\bm{x}(t),\bm{u}(t),t) \leq 0\\
& & & \bm{x}_{lb}\leq \bm{x}(t) \leq \bm{x}_{ub}\\
& & & \bm{x}(0)=\bm{x}_{i}\\
& & & \bm{x}(T)=\bm{x}_{f}\\
\end{aligned}
\end{equation}
%
where $\bm{U}\subset\real^{n}$ defines the admissible control domain, $\L(\cdot)$ stands for the integrand of the path integral along the entire trajectory, $\phi(\cdot)$ is the boundary objective function, $\bm{h}(\cdot) \in \real^{p}$ are the path constraints, and the dynamics of the robot is expressed in its state equation form as
%
\begin{equation}
\label{eq:dyn0}
\bm{f}(\bm{x}(t),\bm{u}(t))=
\begin{bmatrix}\dot{\bm{q}}(t)
\\ \ddot{\bm{q}}(t)
\end{bmatrix} \in \real^{2n}, 
\end{equation}
%
with
%
\begin{equation}\label{eq:dynamics}
\ddot{\bm{q}}(t)=\bm{H}(\bm{q}(t))^{-1}(\bm{u}(t)-\bm{C}(\bm{q}(t),\dot{\bm{q}}(t))\dot{\bm{q}}-\bm{g}(\bm{q}(t)))
\end{equation}
%
where $\bm{H}(\bm{q}) \in \real^{n \times n}$ denotes the inertia matrix, $\bm{C}(\bm{q},\dot{\bm{q}}) \in \real^{n}$ contains the Coriolis and centrifugal forces, $\bm{g}(\bm{q}) \in \real^{n} $ stands for the gravitational terms, and $\bm{u}$ is the generalized input torques. The constraint vectors $\bm{x}_{lb} \in \real^{2n} $ and $\bm{x}_{ub} \in \real^{2n}$ are the lower and upper bounds of the states of the system, and  $\{\bm{x}_{i},\bm{x}_{f}\} \in \real^{2n}$ are the initial and final states.\\

\section{Direct collocation formulation}

The use of direct collocation methods for the transcription of the optimal control problems allows to define the following numerical optimization problem:

\begin{eqnarray} \label{eq:discrete}
\begin{aligned}
&\underset{\bm{z} }{\text{minimize}}  
& &\omega(\bm{z})\\
& \text{subject to} & & \bm{c}_{L} \leq \bm{c}(\bm{z}) \leq \bm{c}_{U}\\ 
& & & \bm{x}_{lb}\leq \bm{x}_{k} \leq \bm{x}_{ub}, \ \ \forall k\in\mathbb{N} \\
& & & \bm{u}_{lb}\leq \bm{u}_{k} \leq \bm{u}_{ub}, \ \ \forall k\in\mathbb{N} \\
\end{aligned}
\end{eqnarray}


\noindent where $\bm{z} \in \real^{n_{decVar}}$ contains the NLP decision variables, $\bm{c}(\bm{z}) \in \real^{nCns}$ stands for the NLP constrains vector, and  $\{\bm{c_L},\bm{c_U}\} \in \real^{n_{cns}}$ are the lower and upper bounds of this vector. The structure and dimensions of this transcribed problem depends entirely of the collocation method applied.\\


\noindent The dynamics of the system are expressed as a finite group of collocation constraints
%
\begin{equation}
\bm{\Phi}=\begin{bmatrix}
\bm{\varphi}_{0} \\ 
\bm{\varphi}_{1} \\ 
\vdots \\
\bm{\varphi}_{N-1}  
\end{bmatrix}\in \real^{2n(N-1)}
\end{equation} 
%
with
%
\begin{equation}\label{eq:collocationcns}
\bm{\varphi}_{k}=\bm{x}_{k+1}-\bm{x}_{k} - h\sum_{i=1}^{s}\beta_{i} \bm{b}_{i}
\end{equation}
%
where

\begin{eqnarray}
\bm{b}_{0}&=&\bm{x}_{k}\\
\bm{b}_{i}&=&\bm{f}\left(\bm{x}_{k}+h \sum_{j=1}^{s}a_{ij}\bm{b}_{j},t_{k}+c_{i}h \right), \ i=1,\hdots,s.
\end{eqnarray}

\noindent $c_{i}$, $a_{ij}$ y $\beta_{i}$ stands for the Butcher's array coefficient for a Runge-Kutta method of order $s$, and
%
\begin{equation}\label{eq:dynamics_discrete}
\bm{f}(\bm{x}_k,\bm{u}_k,t_k)=\begin{bmatrix}\dot{\bm{q}}_k
\\ \bm{H}(\bm{q}_k)^{-1}(\bm{u}_k-\bm{h}(\bm{q}_k,\dot{\bm{q}}_k)
\end{bmatrix} 
\end{equation}
%
The path constraints are expressed as algebraic equations and are enforced at each collocation point
%
\begin{equation}\label{eq:path_vec}
\bm{\gamma}=\begin{bmatrix}
\bm{g}_{0} \\
\bm{g}_{1} \\ 
\vdots \\
\bm{g}_{N}
\end{bmatrix} \in \real^{pN}
\end{equation}
%
with 
%
\begin{equation}\label{eq:pathcns}
\bm{g}_{k}=\bm{g}(\bm{x}_{k},\bm{u}_{k},t_{k}).
\end{equation}
%
The boundary or event constraints are defined only at the the initial $t_0$ and final time $t_f$
%
\begin{equation}\label{eq:event}
\bm{e}=\begin{bmatrix}
\bm{x}_{0}\\
\bm{x}_{N} 
\end{bmatrix}  \in \real^{4n}
\end{equation} 
%
Finally, the NLP constraints vector is defined as
%
\begin{equation}\label{eq:cnsvector}
\bm{c}(\bm{z})=\begin{bmatrix}
\bm{\Phi} \\ 
\bm{\gamma} \\  
\bm{e} 
\end{bmatrix} \in \real^{n_{cns}}
\end{equation}
%
with its boundaries
%
\begin{eqnarray}
\bm{c}_{L}=[\bm{0} \ \bm{0} \ ... \ \bm{0} \ \bm{g}_{L} \ \bm{g}_{L} \ ... \ \bm{g}_{L} \ \bm{x}_{i} \ \bm{x}_{f}]^T\in \mathbb{R}^{n_{cns}}\\
\bm{c}_{U}=[\bm{0} \ \bm{0} \ ... \ \bm{0} \ \bm{g}_{U} \ \bm{g}_{U} \ ... \ \bm{g}_{U} \ \bm{x}_{i} \ \bm{x}_{f}]^T \in \mathbb{R}^{n_{cns}}
\end{eqnarray}

\section{Trapezoidal collocation method}

\subsection{Dimensional analysis of the trapezoidal collocation method}

\begin{center}
$n_{decVar}=N(n_s+n_u)+2$\\
\vspace{1.5mm}
$n_{cns}=n_s(N-1)+pN+4n_s$\\
\vspace{1.5mm}
$n_{colPoints}=N$\\
\vspace{1.5mm}
$n_{colCns}=n_s(N-1)$
\end{center}

\subsection{Trapezoidal cost function}

Recall the Bolza form of the cost function:

\begin{equation}
     \phi(\bm{x}(0),\bm{x}(T),t_0,t_F)+\int_{0}^{T} \L(\bm{x}(t),\bm{u}(t),t) dt
\end{equation}

\noindent To approximate the integral part (known as the Lagrange term) is possible to apply the trapezoidal quadrature

\begin{equation}\label{eq:trap_quad}
    \int_{0}^{T} \L(\bm{x}(t),\bm{u}(t),t) dt =\sum_{k=0}^{N-1}\frac{h_k}{2}(\L_{k+1}+\L_{k})
\end{equation}

\noindent with $\L_k\equiv \L(\bm{x}_{k},\bm{u}_{k},t_{k})$, $h_k=t_{k+1}-t_k$.

\newpage
\noindent Extending the discrete approximation leads to:

\begin{eqnarray*}
  \sum_{k=0}^{N-1}\frac{h_k}{2}(\L_{k+1}+\L_{k}) &=& \frac{1}{2}(h_0\L_0+h_0\L_1+h_1\L_1+h_1\L_2+...+h_{N-1}\L_{N-1}+h_{N-1}\L_{N})\\
   &=& \frac{1}{2}(h_0\L_0+(h_0+h_1)\L_1+(h_1+h_2)\L_2+...+(h_{N-2}+h_{N-1})\L_{N-1}+h_{N-1}\L_{N})\\
   &=& \frac{1}{2}(w_0\L_0+w_1\L_1+w_1\L_2+...+w_{N-1}\L_{N-1}+w_{N}\L_{N})
\end{eqnarray*}

\noindent where $w_k$ are known as the quadrature weights for the trapezoidal rule and are defined as:
\begin{eqnarray*}
   w_0&=&h_0\\
   w_N&=&h_{N-1}\\
   w_k&=&h_{k-1}+h_k \hspace{0.5cm} for \ \ k=1...(N-1)
\end{eqnarray*}

\noindent Let's now define $h_k=(\Delta t \Delta \tau_k)=(t_F-t_0)(\tau_{k+1}+\tau_{k})$ where $0\leq \tau_k\leq 1$ and $\Delta t \geq \Delta \tau_k $. Rewriting the quadrature using this definition leads to:

\begin{equation}\nonumber
    \frac{\Delta t}{2}\left(\Delta\tau_0\L_0+(\Delta\tau_0+\Delta \tau_1)\L_1+(\Delta\tau_1+\Delta\tau_2)\L_2+...+(\Delta\tau_{N-2}+\Delta\tau_{N-1})\L_{N-1}+\Delta\tau_{N-1}\L_{N}\right)
\end{equation}

\noindent Using some basic algebra is possible to rewrite the quadrature weights as:

\begin{eqnarray*}
   w_0&=&\Delta\tau_0\\
   w_N&=&\Delta\tau_{N-1}\\
   w_k&=&\tau_{k+2}-\tau_k \hspace{0.5cm} for \ \ k=0...(N-2)
\end{eqnarray*}

This allows to define the quadrature that nocs applies to compute the Lagrange term approximation for the trapezoidal collocation method

\begin{equation}
   \int_{0}^{T} \L(\bm{x}(t),\bm{u}(t),t) dt= \frac{1}{2}(w_0\L_0+w_{N}\L_{N}+\sum_{k=1}^{N-1} w_k\L_k)
\end{equation}

\subsubsection{Analytical gradients of the trapezoidal quadrature on nocs}

Recall the extended approximation applied in nocs for the trapezoidal quadrature

\begin{equation}
    L=\frac{\Delta t}{2}(w_0\L_0+w_1\L_1+w_1\L_2+...+w_{N-1}\L_{N-1}+w_{N}\L_{N})
\end{equation}

\noindent and define the structure of the gradient of this function w.r.t to the NLP decision variables $\bm{z}\ \in \real^{n_{decVar}}$ as:

\begin{equation} \nonumber
    \nabla_{\bm{z}} L =\begin{bmatrix}
\nabla_{t_{0}} L & \nabla_{t_{F}}L & \nabla_{x_{0}} L & \nabla_{u_{0}} L & \hdots & \nabla_{x_{N}} L & \nabla_{u_{N}} L
\end{bmatrix}^T \in \real^{n_{decVar}}
\end{equation}

\newpage

\noindent Then, the gradients of the trapezoidal w.r.t. the initial ($t_0$) and final times ($t_F$) are defined as:

\begin{eqnarray}
   \nabla_{t_{0}}L&=&\frac{\mathrm{d} L}{\mathrm{d} t_0} = -\frac{1}{2}(w_0\L_0+w_{N}\L_{N}+\sum_{k=1}^{N-1} w_k\L_k) \in  \real\\
   \nabla_{t_{F}}L&=&\frac{\mathrm{d} L}{\mathrm{d} t_F} = - \nabla_{t_{0}} L \in \real
   \end{eqnarray}
   
\noindent In the other hand, the gradients w.r.t. the states $\bm{x}_k$ and control variables $\bm{u}_k$ can be easily computed by taking advantage of the local dependency of the function $\L_k$

\begin{eqnarray}
   \nabla_{\bm{x}_k}L&=&\frac{w_k}{2}(\frac{\partial \L_k}{\partial \bm{x}_k}) \in  \real ^{n_s}\\
   \nabla_{\bm{u}_k}L&=&\frac{w_k}{2}(\frac{\partial \L_k}{\partial \bm{u}_k}) \in  \real ^{n_u}
\end{eqnarray}


\subsection{Constrained system}
Let us define the following functions, called in the literature as the trapezoidal constrained system:

\begin{eqnarray}
    \bm{\zeta_k} &=&\bm{x}_{k+1}-\bm{x}_{k}- \frac{h_k}{2}(\bm{f}_{k+1}+\bm{f}_{k}) \in \real^{n_s} \\
    \bm{\zeta_k} &=&\bm{x}_{k+1}-\bm{x}_{k}- \frac{(t_F-t_0) (\tau_{k+1}-\tau_k)}{2}(\bm{f}_{k+1}+\bm{f}_{k})\\
    \bm{\zeta_k} &=&\bm{x}_{k+1}-\bm{x}_{k}- \frac{\Delta t \Delta \tau_k}{2}(\bm{f}_{k+1}+\bm{f}_{k})\\
    \bm{\zeta_k} &=&[\bm{x}_{k+1}-\bm{x}_{k}]- [\frac{\Delta\tau_k}{2}(\Delta t\bm{f}_{k})]- [\frac{\Delta\tau_k}{2}(\Delta t\bm{f}_{k+1})] \label{eq:trapSeparability}
\end{eqnarray}

\noindent Using the equation (\ref{eq:trapSeparability}) the constrains vector (\ref{eq:cnsvector}) can be rewritten as

\begin{equation}
    \bm{A}\bm{z} + \bm{B}\bm{\bm{y}(\bm{z})}
\end{equation}

\noindent where the dimensions of two constant matrices $A$ and $B$ and the non-linear vector $\bm{y}(\bm{z})$ are \\
$\bm{A} \in \real^{n_{cns} \times n_{decVar}}$ \\
$\bm{B} \in \real^{n_{cns} \times (n_{colPoints})(n_s + p))+n_e+1}$ \\
$\bm{y}(\bm{z}) \in \real^{(n_{colPoints})(n_s + p))+4n_s+1}$\\   

\noindent Under some analysis, is straightforward to determine that the structure of the constant matrices are

\begin{eqnarray} \label{eq:matrixA_trap}
\bm{A}= \begin{bmatrix}
\bm{0}_{n_s \times 2}&\bm{-I}_{n_s \times n_s} &\bm{0}_{n_s \times n_u} &\bm{I}_{n_s \times n_s}\\
& & & \bm{-I}_{n_s \times n_s} &\bm{0}_{n_s \times n_u} &\bm{I}_{n_s \times n_s}\\
\vdots& & & & & & \ddots\\
\bm{0}_{n_s\times 2}& & & & & & & \bm{-I}_{n_s \times 2} &\bm{0}_{n_s \times n_u} &\bm{I}_{n_s \times n_s}\\
\\
\end{bmatrix}
\end{eqnarray}

\begin{equation}
\bm{B}=-\frac{1}{2}
\begin{bmatrix}
 \Delta \tau_0\bm{I}_{n_s \times n_s}  & \Delta \tau_0\bm{I}_{n_s \times n_s} &  &  & \\ 
 & \Delta \tau_1\bm{I}_{n_s \times n_s}& \Delta \tau_1\bm{I}_{n_s \times n_s}   & \\ 
 &    & &  \ddots  \\ 
 &    & & & \Delta \tau_{(N-1)}\bm{I}_{n_s \times n_s}&\Delta \tau_{(N-1)}\bm{I}_{n_s \times n_s}\\ 
 &    & & & & &\bm{I}_{(pN+n_e) \times (pN+n_e)}\\
\end{bmatrix}
\end{equation}
%
and the non-linear vector is defined as:

\begin{equation}
\bm{y}(\bm{z})=\begin{bmatrix}
\bar{\bm{f}}\\
\bm{\gamma}\\
\bm{e}
\end{bmatrix} 
\end{equation}
%
where $\bar{\bm{f}} = \left[ \Delta t\bm{f}_{1}^T \ \ \Delta t\bm{f}_{2}^T \ \ \Delta t\bm{f}_{3}^T \ \ \cdots \ \ \Delta t\bm{f}_{N}^T \right]^T \in \real^{n_sN}$ 

\subsection{The propagation algorithm for the construction of A and B}

For simplicity, let us define a block matrix as

\begin{eqnarray}
\bm{A}_k= \begin{bmatrix}
\bm{-I}_{n_s \times n_s} &\bm{0}_{n_s \times n_u} &\bm{I}_{n_s \times n_s}\\
\end{bmatrix} \in \real^{n_s \times (2n_s + n_u)}
\end{eqnarray}

\noindent And its triplet $a \in \real^{3\times a_{nz}}$representation can be defined as

\begin{table}[h]
\begin{center}
\begin{tabular}{c|c|c}
Row    & Column        & Value \\ \hline
i      & j             & -1    \\
i+1    & j+1           & -1    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
i+$n_s$ & j+$n_s$        & -1    \\
i      & j+ $n_s$+$n_u$  & 1     \\
i+1    & j+$n_s$+$n_u$+1 & 1     \\
 $\vdots$ & $\vdots$     &    $\vdots$     \\
i+$n_s$ & j+$2n_s$+$n_u$  & 1    
\end{tabular}
\end{center}
\end{table}

where $a_{nz}=2n_s$ is the number of non-zero elements in the block matrix $A_k$.

To construct the matrix (\ref{eq:matrixA_trap}) is necessary to insert the matrix $A_k$, $N-1$ times, by deduction the number of non-zero elements in the matrix $A$ can be determined as

\begin{equation}
    A_{nz}=a_{nz}(N-1)
\end{equation}

Following the well structured pattern of the $A$ matrix is possible to propagate the triplet $a$ through the $N-1$ points and obtain a close form to the sparsity template of any $A$ matrix independently of the size of the problem:

\begin{table}[h]
\begin{center}
\begin{tabular}{c|c|c}
Row    & Column        & Value \\ \hline
$\alpha$      & $\beta+2$             & -1    \\
$\alpha+1$    & $\beta+3$           & -1    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
$\alpha$+$n_s$ & $\beta+n_s+2$        & -1    \\
$\alpha$      & $\beta+n_s+n_u+2$  & 1     \\
$\alpha+1$    & $\beta+n_s$+$n_u+1 +2$ & 1     \\
 $\vdots$ & $\vdots$     &    $\vdots$     \\
$\alpha+n_s$ & $\beta+2n_s$+$n_u+2$  & 1    
\end{tabular}
\end{center}
\end{table}

\noindent with $\alpha=(k)(n_s)$ and $\beta=(k)(n_s+n_u)$ for $k=0...N-1$
%
\begin{algorithm}
	\caption{Propagation algorithm for A trapezoidal matrix} 
	\begin{algorithmic}[1]
		\For {$k=0,1,\ldots,N-1$}
		    \State $i=0$
		    \State $\alpha=(k)(n_s)$
		    \State $\beta=(k)(n_s+n_u)+2$
			\For {$n_z=0,1,\ldots,n_s$}
			    \State $iRow=\alpha+i$
			    \State $iCol=\beta+i$
				\State Save the information in the triplet ($iRow$, $iCol$, $-1$)
				\State i++
			\EndFor
			\State $i=0$
            \For {$n_z=n_s,n_s+1,\ldots,a_{nz}$}
			    \State $iRow=\alpha+i$
			    \State $iCol=\beta+n_s+n_u+i$
				\State Save the information in the triplet ($iRow$, $iCol$, $1$)
				\State i++
			\EndFor
		\EndFor
	\end{algorithmic} 
\end{algorithm}
%
\newpage
\noindent Now for simplicity define a block matrix

\begin{eqnarray}
\bm{B}_k= \frac{\Delta \tau_k}{2}\begin{bmatrix}
\bm{I}_{n_s \times n_s} &\bm{I}_{n_s \times n_s}\\
\end{bmatrix} \in \real^{n_s \times 2n_s}
\end{eqnarray}

\noindent Following the methodology applied for the matrix $A_k$, the triplet $b \in \real^{3\times b_{nz}}$ (where $b_{nz}=2n_s$) can be defined as:

\begin{table}[h]
\begin{center}
\begin{tabular}{c|c|c}
Row    & Column        & Value \\ \hline
i      & j             & $-\frac{\Delta \tau_k}{2}$    \\
i+1    & j+1           & $-\frac{\Delta \tau_k}{2}$    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
i+$n_s$ & j+$n_s$        & $-\frac{\Delta \tau_k}{2}$    \\
i      & j+$n_s$  & $-\frac{\Delta \tau_k}{2}$     \\
i+1    & j+$n_s$+1 & $-\frac{\Delta \tau_k}{2}$     \\
 $\vdots$ & $\vdots$     &    $\vdots$     \\
i+$n_s$ & j+$2n_s$  & $-\frac{\Delta \tau_k}{2}$    
\end{tabular}
\end{center}
\end{table}

To construct the matrix $B$, is necessary to insert the $B_k$ matrix $N-1$ times and an identity matrix $I_g \in \real^{(pN+n_e) \times (pN+n_e) }$. The number of non-zero elements in the $B$ matrix can be computed as:

\begin{equation}
    B_{nz}=(2n_s)(N-1)+pN+n_e
\end{equation}

Following the pattern of the $B$ matrix is possible to propagate the triplet $b$ through the $N-1$ points and insert the $I_g$ matrix to obtain a close form sparsity template of any $B$ matrix, independently of the size of the problem:

\begin{table}[h]
\begin{center}
\begin{tabular}{c|c|c}
Row    & Column        & Value \\ \hline
$\eta$      & $\nu+2$             & $-\frac{\Delta \tau_k}{2}$    \\
$\eta+1$    & $\nu+1$           & $-\frac{\Delta \tau_k}{2}$    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
$\eta$+$n_s$ & $\nu+n_s$        &$-\frac{\Delta \tau_k}{2}$   \\
$\eta$      & $\nu+n_s+n_u+2$  & $-\frac{\Delta \tau_k}{2}$   \\
$\eta+1$    & $\nu+n_s$+$n_u+1 +2$ & $-\frac{\Delta \tau_k}{2}$     \\
 $\vdots$ & $\vdots$     &    $\vdots$     \\
$\eta+n_s$ & $\nu+2n_s$+$n_u$  & $-\frac{\Delta \tau_k}{2}$  \\
 $\vdots$ & $\vdots$     &    $\vdots$     \\
$n_{colCns}$      & $(n_s)(n_{colPoints})$             & $1$    \\
$n_{colCns}+1$      & $(n_s)(n_{colPoints})+1$             & $1$    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
$n_{colCns}+nP+n_e$      & $(n_s)(n_{colPoints})+nP+n_e$             & $1$    \\
\end{tabular}
\end{center}
\end{table}

\noindent with $\eta=\nu=(k)(n_s)$ for $k=0...N-1$

\begin{algorithm}
	\caption{Propagation algorithm for B trapezoidal matrix} 
	\begin{algorithmic}[1]
		\For {$k=0,1,\ldots,N-1$}
		    \State $i=0$
		    \State $\eta=(k)(n_s)$
		    \State $\nu=(k)(n_s)$
			\For {$n_z=0,1,\ldots,n_s$}
			    \State $iRow=\eta+i$
			    \State $iCol=\nu+i$
				\State Save the information in the triplet ($iRow$, $iCol$, $-0.5 \Delta \tau_k$)
				\State i++
			\EndFor
			\State $i=0$
            \For {$n_z=n_s,n_s+1,\ldots,2n_s$}
			    \State $iRow=\eta+i$
			    \State $iCol=\nu+n_s+i$
				\State Save the information in the triplet ($iRow$, $iCol$, $-0.5 \Delta \tau_k$)
				\State i++
			\EndFor
		\EndFor
		\State $i=0$
		\For {$n_z=(2n_s)(N-1),\ldots,B_{nz}$}
		        \State $iRow=n_{colCns}+i$
			    \State $iCol=(n_s)(n_{colPoints})+i$
				\State Save the information in the triplet ($iRow$, $iCol$, $1$)
				\State i++
		\EndFor
	\end{algorithmic} 
\end{algorithm}

\section{Hermite-Simpson Separated (HSS) collocation method}

\subsection{Dimensional analysis of the HSS collocation method}

\begin{center}
$n_{colPoints}=2N-1$\\
\vspace{1.5mm}
$n_{decVar}=(n_{colPoints})(n_s+n_u)+2$\\
\vspace{1.5mm}
$n_{colCns}=n_s(n_{colPoints}-1)$\\
\vspace{1.5mm}
$n_{cns}=n_{colCns}+p(n_{colPoints})+n_e$\\
\end{center}

\subsection{Hermite-Simpson cost function}

Recall the Bolza form of the cost function:

\begin{equation}
     \phi(\bm{x}(0),\bm{x}(T),t_0,t_F)+\int_{0}^{T} \L(\bm{x}(t),\bm{u}(t),t) dt
\end{equation}

\noindent To approximate the integral part (known as the Lagrange term) is possible to apply the trapezoidal quadrature

\begin{equation}\label{eq:trap_quad}
    \int_{0}^{T} \L(\bm{x}(t),\bm{u}(t),t) dt =\sum_{k=0}^{N-1}\frac{h_k}{6}(\L_{k+1}+4\bar{\L}_{k}+\L_{k})
\end{equation}

\noindent with $\L_k\equiv \L(\bm{x}_{k},\bm{u}_{k},t_{k})$,$\bar{\L}_k\equiv \L(\bm{x}_{k+\frac{1}{2}},\bm{u}_{k+\frac{1}{2}},t_{k+\frac{1}{2}} )$ ,  $h_k=t_{k+1}-t_k$.\\

\noindent Extending the discrete approximation leads to:

\begin{eqnarray*}
  \sum_{k=0}^{N-1}\frac{h_k}{6}(\L_{k}+4\bar{\L}_{k}+\L_{k+1}) &=& \frac{1}{6}(h_0\L_0+4h_0\bar{\L}_0+h_0\L_1+ h_1\L_1+4h_1\bar{\L}_1+h_1\L_2+ ...\\ &...& +h_{N-1}\L_{N-1}+4h_{N-1}\bar{\L}_{N-1}+h_{N-1}\L_N)\\
  &=&\frac{1}{6}(h_0\L_0+4h_0\bar{\L}_0+(h_0+h_1)\L_1+4h_1\bar{\L}_1+(h_1+h_2)\L_2+ ...\\ &...& +(h_{N-2}+h_{N-1})\L_{N-1}+4h_{N-1}\bar{\L}_{N-1}+h_{N-1}\L_N)\\
  &=&\frac{1}{6}(w_0\L_0+\bar{w}_0\bar{\L}_0+w_1\L_1+\bar{w}_1\bar{\L}_1+w_2\L_2+ ...\\ &...& +w_{N-1}\L_{N-1}+\bar{w}_{N-1}\bar{\L}_{N-1}+w_N\L_N)
\end{eqnarray*}

\noindent where $w_k$ are known as the quadrature weights for the Simpson rule and are defined as:
\begin{eqnarray*}
   w_0&=&h_0\\
   w_N&=&h_{N-1}\\
   \bar{w}_k&=&4h_k \hspace{1.6cm}  for \ \ k=0...(N-1)\\
   w_k&=&h_{k-1}+h_k \hspace{0.5cm} for \ \ k=1...(N-1)
\end{eqnarray*}

\noindent Let's now define $h_k=(\Delta t \Delta \tau_k)=(t_F-t_0)(\tau_{k+1}+\tau_{k})$ where $0\leq \tau_k\leq 1$ and $\Delta t \geq \Delta \tau_k $. Rewriting the quadrature using this definition leads to:

\begin{eqnarray*}
   w_0&=&\Delta\tau_0\\
   w_N&=&\Delta\tau_{N-1}\\
   \bar{w}_k&=&4\Delta\tau_k \hspace{1.2cm}  for \ \ k=0...(N-1)\\
   w_k&=&\tau_{k+2}-\tau_k \hspace{0.5cm} for \ \ k=0...(N-2)
\end{eqnarray*}

\noindent This allows to define the quadrature that NOCS applies to compute the Lagrange term approximation for the trapezoidal collocation method

\begin{equation}
   \int_{0}^{T} \L(\bm{x}(t),\bm{u}(t),t) dt= \frac{1}{6}(w_0\L_0+w_{N}\L_{N}+\sum_{k=0}^{N-1} \bar{w}_k\bar{\L}_k+\sum_{k=1}^{N-1} w_k\L_k)
\end{equation}

\subsubsection{Analytical gradients of the Simspon quadrature on NOCS}

Recall the extended approximation applied in NOCS for the Simpson quadrature

\begin{equation}
    L=\frac{1}{6}(w_0\L_0+\bar{w}_0\bar{\L}_0+w_1\L_1+\bar{w}_1\bar{\L}_1+w_2\L_2+ ...+w_{N-1}\L_{N-1}+\bar{w}_{N-1}\bar{\L}_{N-1}+w_N\L_N)
\end{equation}

\noindent and define the structure of the gradient $\nabla_{\bm{z}}L \in \real ^{n_{decVar}}$ of this function w.r.t to the NLP decision variables $\bm{z}\ \in \real^{n_{decVar}}$ as:

\begin{equation} \nonumber
    \nabla_{\bm{z}} L =\begin{bmatrix}
\nabla_{t_{0}} L & \nabla_{t_{F}}L & \nabla_{x_{0}} L & \nabla_{u_{0}} L & \nabla_{x_{0.5}} L & \nabla_{u_{0.5}} L & \hdots & \nabla_{x_{N-\frac{1}{2}}} L & \nabla_{u_{N-\frac{1}{2}}} L & \nabla_{x_{N}} L & \nabla_{u_{N}} L
\end{bmatrix}^T
\end{equation}

\noindent Then, the gradients of the Simpson quadrature w.r.t. the initial ($t_0$) and final times ($t_F$) are defined as:

\begin{eqnarray}
   \nabla_{t_{0}}L&=&\frac{\mathrm{d} L}{\mathrm{d} t_0} = -\frac{1}{6}(w_0\L_0+w_{N}\L_{N}+\sum_{k=1}^{N-1} w_k\L_k) \in  \real\\
   \nabla_{t_{F}}L&=&\frac{\mathrm{d} L}{\mathrm{d} t_F} = - \nabla_{t_{0}} L \in \real
   \end{eqnarray}
   
\noindent In the other hand, the gradients w.r.t. the states $\bm{x}_k$ and control variables $\bm{u}_k$ can be easily computed by taking advantage of the local dependency of the function $\L_k$

\begin{eqnarray}
   \nabla_{\bm{x}_k}L&=&\frac{w_k}{6}(\frac{\partial \L_k}{\partial \bm{x}_k}) \in  \real ^{n_s}\\
   \nabla_{\bm{u}_k}L&=&\frac{w_k}{6}(\frac{\partial \L_k}{\partial \bm{u}_k}) \in  \real ^{n_u}
\end{eqnarray}

\subsection{Constrained system}
Let us define the following functions, called in the literature as the Hermite-Simpson constrained system:

\begin{eqnarray}
    \bm{\zeta_{k,0}} &=&\bm{x}_{k+1}-\bm{x}_{k}- \frac{h_k}{6}(\bm{f}_{k}+4\bm{f}_{k+\frac{1}{2}}+\bm{f}_{k+1}) \in \real^{n_s} \label{eq:simpson_quadrature}\\
    \bm{\zeta_{k,1}} &=&\bm{x}_{k+\frac{1}{2}}-\frac{1}{2}(\bm{x}_{k}+\bm{x}_{k+1})- \frac{h_k}{8}(\bm{f}_{k}-\bm{f}_{k+1}) \in \real^{n_s} \label{eq:hermite_interpolant}
\end{eqnarray}

\noindent where $\bm{\zeta_{k,0}}$ is known as the Simpson's quadrature and $\bm{\zeta_{k,1}}$ is the well known Hermite's interpolant.\\

\noindent By rearranging the HSS constrained system

\begin{eqnarray}
    \bm{\zeta_{k,0}} &=&\bm{x}_{k+1}-\bm{x}_{k}- \frac{\Delta\tau_k \Delta t}{6}(\bm{f}_{k}+4\bm{f}_{k+\frac{1}{2}}+\bm{f}_{k+1}) \nonumber\\
    \bm{\zeta_{k,1}} &=&\bm{x}_{k+\frac{1}{2}}-\frac{1}{2}(\bm{x}_{k}+\bm{x}_{k+1})- \frac{\Delta\tau_k \Delta t}{8}(\bm{f}_{k}-\bm{f}_{k+1}) \nonumber
\end{eqnarray}
\begin{eqnarray}
    \bm{\zeta_{k,0}} &=&[\bm{x}_{k+1}-\bm{x}_{k}]- [\frac{\Delta\tau_k \Delta t}{6}\bm{f}_{k}] -[\frac{2\Delta\tau_k \Delta t}{3}\bm{f}_{k+\frac{1}{2}}]-[\frac{\Delta\tau_k \Delta t}{6}\bm{f}_{k+1}]\\
    \bm{\zeta_{k,1}} &=&[\bm{x}_{k+\frac{1}{2}}-\frac{1}{2}\bm{x}_{k}-\frac{1}{2}\bm{x}_{k+1}]- [\frac{\Delta\tau_k \Delta t}{8}\bm{f}_{k}]+[\frac{\Delta\tau_k \Delta t}{8}\bm{f}_{k+1}]
\end{eqnarray}

\noindent Following the same procedure as the trapezoidal method, is possible to reconstruct the HSS constrained system as

\begin{equation}
    \bm{A}\bm{z} + \bm{B}\bm{\bm{y}(\bm{z})}
\end{equation}

\noindent where the dimensions of two constant matrices $A$ and $B$ and the non-linear vector $\bm{y}(\bm{z})$ are \\
$\bm{A} \in \real^{n_{cns} \times n_{decVar}}$ \\
$\bm{B} \in \real^{n_{cns} \times (n_{colPoints})(n_s + p))+n_e+1}$ \\
$\bm{y}(\bm{z}) \in \real^{(n_{colPoints})(n_s + p))+n_e+1}$\\   

\noindent Under the same analysis, the structure of the constant matrices is

\begin{equation}
    \bm{A}= \begin{bmatrix}
 \bm{0}_{n_s \times 2}& -\frac{1}{2}\bm{I} & \bm{0} & \bm{I} & \bm{0} & -\frac{1}{2}\bm{I} &  &  &  &  &  &  &  &  &  & \\ 
 \bm{0}_{n_s \times 2}& -\bm{I} & \bm{0} &  & \bm{0} & \bm{I} &  &  &  &  &  &  &  &  &  & \\ 
 &  &  &  &  & -\frac{1}{2}\bm{I} & \bm{0} & \bm{I}& \bm{0} & -\frac{1}{2}\bm{I} &  &  &  &  &  & \\ 
 &  &  &  &  & -\bm{I} & \bm{0} &  & \bm{0} & \bm{I} &  &  &  &  &  & \\ 
 &  &  &  &  &  &  &  &  &  & \ddots &  &  &  &  & \\ 
 &  &  &  &  &  &  &  &  &  &  & -\frac{1}{2}\bm{I} & \bm{0} & \bm{I} & \bm{0} & -\frac{1}{2}\bm{I} \\ 
 &  &  &  &  &  &  &  &  &  &  & -\bm{I} & \bm{0} &  & \bm{0} & \bm{I} 
\end{bmatrix} \nonumber
\end{equation}

\begin{equation}
\bm{B}=\begin{bmatrix}
 -\frac{\Delta \tau_0}{8}\bm{I}& \bm{0}_{n_s} & \frac{\Delta \tau_0}{8}\bm{I} &  &  &  &  &  & \\ 
 -\frac{\Delta \tau_0}{6}\bm{I}& -\frac{2\Delta \tau_0}{3}\bm{I} & -\frac{\Delta \tau_0}{6}\bm{I} &  &  &  &  &  & \\ 
 &  & -\frac{\Delta \tau_1}{8}\bm{I} & \bm{0}_{n_s} & \frac{\Delta \tau_1}{8}\bm{I} &  &  &  & \\ 
 &  & -\frac{\Delta \tau_1}{6}\bm{I} & -\frac{2\Delta \tau_1}{3}\bm{I} & -\frac{\Delta \tau_1}{6}\bm{I} &  &  &  & \\ 
 &  &  &  &  & \ddots &  &  & \\ 
 &  &  &  &  &  & -\frac{\Delta \tau_{N-1}}{8}\bm{I} & \bm{0}_{n_s} & \frac{\Delta \tau_{(N-1)}}{8}\bm{I}\\ 
 &  &  &  &  &  & -\frac{\Delta \tau_{(N-1)}}{6}\bm{I} & -\frac{2\Delta \tau_{N-1}}{3}\bm{I} & -\frac{\Delta \tau_{(N-1)}}{6}\bm{I}
\end{bmatrix} \nonumber
\end{equation}

and the non-linear vector is defined as:

\begin{equation}
\bm{y}(\bm{z})=\begin{bmatrix}
\bar{\bm{f}}\\
\bm{\gamma}\\
\bm{e}
\end{bmatrix} 
\end{equation}
%
where $\bar{\bm{f}} = \left[ \Delta t\bm{f}_{1}^T \ \ \ \Delta t\bm{f}_{1.5}^T \ \ \Delta t\bm{f}_{2}^T \ \ \ \Delta t\bm{f}_{2.5}^T \ \ \Delta t\bm{f}_{3}^T \ \ \ \Delta t\bm{f}_{3.5}^T \ \ \cdots \ \ \Delta t\bm{f}_{N}^T \right]^T \in \real^{n_s(n_{colPoints})}$, $\bm{I} \in \real^{n_s \times n_s}$ is an identity matrix, $\bm{0} \in \real^{n_s \times n_u}$ and $\bm{0}_{ns} \in \real^{n_s \times n_s}$ are null matrices. 

\newpage

\subsection{The propagation algorithm for the construction of A and B}

For simplicity, let us define a block matrix as


\begin{eqnarray}
\bm{A_k}= \begin{bmatrix}
-\frac{1}{2}\bm{I} &\bm{0} &\bm{I} &\bm{0} &-\frac{1}{2}\bm{I}\\
 \bm{-I} &\bm{0} & & \bm{0} &\bm{I} \\
\end{bmatrix} \in \real^{2n_s \times (3n_s + 2n_u)}
\end{eqnarray}

\noindent And its triplet $a \in \real^{3\times a_{nz}}$representation can be defined as

\begin{table}[h]
\begin{center}
\begin{tabular}{c|c|c}
Row    & Column        & Value \\ \hline
i      & j             & -0.5    \\
i+1    & j+1           & -0.5    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
i+$n_s$ & j+$n_s$        & -0.5    \\
i      & j+ $n_s$+$n_u$  & 1     \\
i+1    & j+$n_s$+$n_u$+1 & 1     \\
 $\vdots$ & $\vdots$     &    $\vdots$     \\
i+$n_s$ & j+$2n_s$+$n_u$  & 1\\
i & j+$2n_s+2n_u$        & -0.5    \\
i+1 & j+$2n_s+2n_u$+1        & -0.5    \\
 $\vdots$ & $\vdots$     &    $\vdots$     \\
i+$n_s$    & j+$3n_s$+$2n_u$ & -0.5     \\
i+ $n_s$ & j        & -1    \\
i+$n_s$+1 & j+1        & -1    \\
 $\vdots$ & $\vdots$     &    $\vdots$     \\
i+$2n_s$    & j+$n_s$ & -1     \\
i+ $n_s$ & j+$2n_s$+$2n_u$        & 1    \\
i+$n_s$+1 & j+$2n_s$+$2n_u$+1        & 1    \\
 $\vdots$ & $\vdots$     &    $\vdots$     \\
i+$2n_s$    &j+$3n_s$+$2n_u$ & 1     \\
\end{tabular}
\end{center}
\end{table}

where $a_{nz}=5n_s$ is the number of non-zero elements in the block matrix $A_k$.

To construct the matrix A is necessary to insert the matrix $A_k$, $N-1$ times, by deduction the number of non-zero elements in the matrix $A$ can be determined as

\begin{equation}
    A_{nz}=5n_s(N-1)
\end{equation}

Once again, following the pattern of the $A$ matrix is possible to propagate the triplet $a$ through the $N-1$ points and obtain a close form to the sparsity template of any $A$ matrix independently of the size of the problem:

\newpage

\begin{table}[h]
\begin{center}
\begin{tabular}{c|c|c}
Row    & Column        & Value \\ \hline
$\alpha$      & $\beta+2$             & -0.5    \\
$\alpha$ +1    & $\beta$+3           & -0.5    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
$\alpha$+$n_s$ & $\beta$+$n_s+2$        & -0.5    \\
$\alpha$      & $\beta$+ $n_s$+$n_u+2$  & 1     \\
$\alpha$+1    & $\beta$+$n_s$+$n_u$+3 & 1     \\
 $\vdots$ & $\vdots$     &    $\vdots$     \\
$\alpha$+$n_s$ & $\beta$+$2n_s$+$n_u$+2  & 1\\
$\alpha$ & $\beta$+$2n_s+2n_u+2$        & -0.5    \\
$\alpha$+1 & $\beta$+$2n_s+2n_u$+3        & -0.5    \\
 $\vdots$ & $\vdots$     &    $\vdots$     \\
$\alpha$+$n_s$    & $\beta$+$3n_s$+$2n_u$+2 & -0.5     \\
$\alpha$+ $n_s$ & $\beta+2$        & -1    \\
$\alpha$+$n_s$+1 & $\beta$+3        & -1    \\
 $\vdots$ & $\vdots$     &    $\vdots$     \\
$\alpha$+$2n_s$    & $\beta$+$n_s$+2 & -1     \\
$\alpha$+ $n_s$ & $\beta$+$2n_s$+$2n_u$+2        & 1    \\
$\alpha$+$n_s$+1 & $\beta$+$2n_s$+$2n_u$+3        & 1    \\
 $\vdots$ & $\vdots$     &    $\vdots$     \\
$\alpha$+$2n_s$    &$\beta$+$3n_s$+$2n_u$+2 & 1     \\
\end{tabular}
\end{center}
\end{table}

\noindent with $\alpha=(2k)(n_s)$ and $\beta=(k)(2(n_s+n_u))$ for $k=0...N-1$
%
\begin{algorithm}
	\caption{Propagation algorithm for A trapezoidal matrix} 
	\begin{algorithmic}[1]
		\For {$k=0,1,\ldots,N-1$}
		    \State $i=0$
		    \State $\alpha=(2k)(n_s)$
		    \State $\beta=(k)(2(n_s+n_u))+2$
			\For {$n_z=0,1,\ldots,n_s$}
			    \State $iRow=\alpha+i$
			    \State $iCol=\beta+i$
				\State Save the information in the triplet ($iRow$, $iCol$, $-0.5$)
				\State i++
			\EndFor
			\State $i=0$
            \For {$n_z=n_s,n_s+1,\ldots,2n_s$}
			    \State $iRow=\alpha+i$
			    \State $iCol=\beta+n_s+n_u+i$
				\State Save the information in the triplet ($iRow$, $iCol$, $1$)
				\State i++
			\EndFor
			\State $i=0$
            \For {$n_z=2n_s,2n_s+1,\ldots,3n_s$}
			    \State $iRow=\alpha+i$
			    \State $iCol=\beta+2n_s+2n_u+i$
				\State Save the information in the triplet ($iRow$, $iCol$, $-0.5$)
				\State i++
			\EndFor
			\State $i=0$
            \For {$n_z=3n_s,3n_s+1,\ldots,4n_s$}
			    \State $iRow=\alpha+n_s+i$
			    \State $iCol=\beta+i$
				\State Save the information in the triplet ($iRow$, $iCol$, $-1$)
				\State i++
			\EndFor
			\State $i=0$
            \For {$n_z=4n_s,4n_s+1,\ldots,a_{nz}$}
			    \State $iRow=\alpha+n_s+i$
			    \State $iCol=\beta+2n_s+2n_u+i$
				\State Save the information in the triplet ($iRow$, $iCol$, $1$)
				\State i++
			\EndFor
			
		\EndFor
	\end{algorithmic} 
\end{algorithm}
%
\newpage
\noindent Now for simplicity define a block matrix

\begin{equation}
\bm{B}_k=\begin{bmatrix}
 -\frac{\Delta \tau_k}{8}\bm{I}& \bm{0}_{n_s} & \frac{\Delta \tau_k}{8}\bm{I} \\ 
 -\frac{\Delta \tau_k}{6}\bm{I}& -\frac{2\Delta \tau_k}{3}\bm{I} & -\frac{\Delta \tau_k}{6}\bm{I}
\end{bmatrix} \nonumber
\end{equation}

\noindent Following the methodology applied for the matrix $A_k$, the triplet $b \in \real^{3\times b_{nz}}$ (where $b_{nz}=5n_s$) can be defined as:

\begin{table}[h]
\begin{center}
\begin{tabular}{c|c|c}
Row    & Column        & Value \\ \hline
i      & j             & $-\frac{\Delta \tau_k}{8}$    \\
i+1    & j+1           & $-\frac{\Delta \tau_k}{8}$    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
i+$n_s$ & j+$n_s$        & $-\frac{\Delta \tau_k}{8}$    \\
%
i      & j+$2n_s$  & $\frac{\Delta \tau_k}{8}$     \\
i+1    & j+$2n_s$+1 & $\frac{\Delta \tau_k}{8}$     \\
 $\vdots$ & $\vdots$     &    $\vdots$     \\
i+$n_s$ & j+$3n_s$  & $\frac{\Delta \tau_k}{8}$\\
%
i+ $n_s$      & j             & $-\frac{\Delta \tau_k}{6}$    \\
i+$n_s$+1    & j+1           & $-\frac{\Delta \tau_k}{6}$    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
i+$2n_s$ & j+$n_s$        & $-\frac{\Delta \tau_k}{6}$    \\
%
i+ $n_s$      & j+$n_s$             & $-\frac{2\Delta \tau_k}{3}$    \\
i+$n_s$+1    & j+$n_s$+1           & $-\frac{2\Delta \tau_k}{3}$    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
i+$2n_s$ & j+$2n_s$        & $-\frac{2\Delta \tau_k}{3}$    \\
%
i+ $n_s$      & j+$2n_s$             & $-\frac{\Delta \tau_k}{6}$    \\
i+$n_s$+1    & j+$2n_s$+1           & $-\frac{\Delta \tau_k}{6}$    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
i+$2n_s$ & j+$3n_s$        & $-\frac{\Delta \tau_k}{6}$    \\
\end{tabular}
\end{center}
\end{table}

To construct the matrix $B$, is necessary to insert the $B_k$ matrix $N-1$ times and an identity matrix $I_g \in \real^{(p(n_{colPoints})+n_e) \times (pN+n_e) }$. The number of non-zero elements in the $B$ matrix can be computed as:

\begin{equation}
    B_{nz}=(5n_s)(N-1)+p(n_{colPoints})+n_e
\end{equation}

Following the pattern of the $B$ matrix is possible to propagate the triplet $b$ through the $N-1$ points and insert the $I_g$ matrix to obtain a close form sparsity template of any $B$ matrix, independently of the size of the problem:

\newpage

\begin{table}[h]
\begin{center}
\begin{tabular}{c|c|c}
Row    & Column        & Value \\ \hline
$\eta$      & $\nu$             & $-\frac{\Delta \tau_k}{8}$    \\
$\eta$+1    & $\nu$+1           & $-\frac{\Delta \tau_k}{8}$    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
$\eta$+$n_s$ & $\nu$+$n_s$        & $-\frac{\Delta \tau_k}{8}$    \\
%
$\eta$      & $\nu$+$2n_s$  & $\frac{\Delta \tau_k}{8}$     \\
$\eta$+1    & $\nu$+$2n_s$+1 & $\frac{\Delta \tau_k}{8}$     \\
 $\vdots$ & $\vdots$     &    $\vdots$     \\
$\eta$+$n_s$ & $\nu$+$3n_s$  & $\frac{\Delta \tau_k}{8}$\\
%
$\eta$+ $n_s$      & $\nu$             & $-\frac{\Delta \tau_k}{6}$    \\
$\eta$+$n_s$+1    & $\nu$+1           & $-\frac{\Delta \tau_k}{6}$    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
$\eta$+$2n_s$ & $\nu$+$n_s$        & $-\frac{\Delta \tau_k}{6}$    \\
%
$\eta$+ $n_s$      & $\nu$+$n_s$             & $-\frac{2\Delta \tau_k}{3}$    \\
$\eta$+$n_s$+1    & $\nu$+$n_s$+1           & $-\frac{2\Delta \tau_k}{3}$    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
$\eta$+$2n_s$ & $\nu$+$2n_s$        & $-\frac{2\Delta \tau_k}{3}$    \\
%
$\eta$+ $n_s$      & $\nu$+$2n_s$             & $-\frac{\Delta \tau_k}{6}$    \\
$\eta$+$n_s$+1    & $\nu$+$2n_s$+1           & $-\frac{\Delta \tau_k}{6}$    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
$\eta$+$2n_s$ & $\nu$+$3n_s$        & $-\frac{\Delta \tau_k}{6}$    \\
 $\vdots$ & $\vdots$     &    $\vdots$     \\
$n_{colCns}$      & $(n_s)(n_{colPoints})$             & $1$    \\
$n_{colCns}+1$      & $(n_s)(n_{colPoints})+1$             & $1$    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
$n_{colCns}+p(n_{colPoints})+n_e$      & $(n_s)(n_{colPoints})+n(n_{colPoints})+n_e$             & $1$    \\
\end{tabular}
\end{center}
\end{table}

\noindent with $\eta=\nu=2(k)(n_s)$ for $k=0...N-1$

\begin{algorithm}
	\caption{Propagation algorithm for B HSS matrix} 
	\begin{algorithmic}[1]
		\For {$k=0,1,\ldots,N-1$}
		    \State $i=0$
		    \State $\eta=(2k)(n_s)$
		    \State $\nu=(2k)(n_s)$
			\For {$n_z=0,1,\ldots,n_s$}
			    \State $iRow=\eta+i$
			    \State $iCol=\nu+i$
				\State Save the information in the triplet ($iRow$, $iCol$, $-\frac{\Delta \tau_k}{8} $)
				\State i++
			\EndFor
			\State $i=0$
            \For {$n_z=n_s,n_s+1,\ldots,2n_s$}
			    \State $iRow=\eta+i$
			    \State $iCol=\nu+2n_s+i$
				\State Save the information in the triplet ($iRow$, $iCol$, $\frac{\Delta \tau_k}{8} $)
				\State i++
			\EndFor
			\State $i=0$
            \For {$n_z=2n_s,2n_s+1,\ldots,3n_s$}
			    \State $iRow=\eta+n_s+i$
			    \State $iCol=\nu+i$
				\State Save the information in the triplet ($iRow$, $iCol$, $-\frac{\Delta \tau_k}{6} $)
				\State i++
			\EndFor
			\State $i=0$
            \For {$n_z=3n_s,3n_s+1,\ldots,4n_s$}
			    \State $iRow=\eta+n_s+i$
			    \State $iCol=\nu+n_s+i$
				\State Save the information in the triplet ($iRow$, $iCol$, $-\frac{2\Delta \tau_k}{3} $)
				\State i++
			\EndFor
			\State $i=0$
            \For {$n_z=4n_s,4n_s+1,\ldots,b_{nz}$}
			    \State $iRow=\eta+n_s+i$
			    \State $iCol=\nu+2n_s+i$
				\State Save the information in the triplet ($iRow$, $iCol$, $-\frac{\Delta \tau_k}{6} $)
				\State i++
			\EndFor
		\EndFor
		\State $i=0$
		\For {$n_z=(5n_s)(N-1),\ldots,B_{nz}$}
		        \State $iRow=n_{colCns}+i$
			    \State $iCol=(n_s)(n_{colPoints})+i$
				\State Save the information in the triplet ($iRow$, $iCol$, $1$)
				\State i++
		\EndFor
		
	\end{algorithmic} 
\end{algorithm}

\newpage

\section{Computation of the Derivative Matrix using the propagation algorithm}

Recall the structure of the constrains vector (Either trapezoidal or HSS)

\begin{equation}
    \bm{c}(\bm{z})=\bm{A}\bm{z} + \bm{B}\bm{\bm{y}(\bm{z})}
\end{equation}

\noindent where $\bm{A}$ and $\bm{B}$ are constant matrices and $\bm{y}(\bm{z})$ is the non-linear vector. Suppose that the Jacobian of the constraints is computed given the following expression

\begin{eqnarray}
   \frac{\partial \bm{c}(\bm{z})}{\partial \bm{z}} =\bm{A} + \bm{B}\frac{\partial \bm{y}(\bm{z})}{\partial \bm{z}}
\end{eqnarray}
\begin{eqnarray}
   \frac{\partial \bm{c}(\bm{z})}{\partial \bm{z}} =\bm{A} + \bm{B}\bm{D}
\end{eqnarray}

\noindent where $\bm{D} \in \real^{(n_{colPoints}(n_s+p)+n_e+1) \times n_{decVar}} $ is known as \textbf{the derivative matrix}. This derivatives matrix exploits the sparsity of the local collocation methods allowing to propose a well-defined structure of the sparsity pattern

\begin{equation} \label{mat:D_structure}
\bm{D}=\begin{bmatrix}
\bm{1}_{n_s \times 2} & \bm{D}_{f_0} &  &  & \\ 
\bm{1}_{n_s \times 2} & \bm{0} & \bm{D}_{f_1} &  & \\ 
\vdots  & \vdots  & \vdots &  \ddots& \\ 
\bm{1}_{n_s \times 2} & \bm{0} & \bm{0} & \hdots & \bm{D}_{f_N}\\ 
\bm{D}_{t_0} \ \bm{D}_{t_F} &  \bm{D}_{e_0}& \bm{0} & \hdots &\bm{D}_{e_N} \\ 
\bm{0} & \bm{D}_{p_0} & \bm{0} &  & \\ 
\bm{0} & \bm{0} &\bm{D}_{p_1}  &  & \\ 
 &  &  &  \ddots& \\ 
 &  &  &  &\bm{D}_{p_N} \\ 
1 \ \ 1 & \bm{0} & \bm{0} & \hdots & \bm{0} 
\end{bmatrix}
\end{equation}

\noindent where

\begin{equation}
    \bm{D}_{f_k}=\Delta t \frac{\partial \bm{f}_k}{\partial \bm{z}_k}= \Delta t 
    \begin{bmatrix}
     \frac{\partial \bm{f}_k}{\partial \bm{x}_k} & \frac{\partial \bm{f}_k}{\partial \bm{u}_k} 
    \end{bmatrix} \in \real^{n_s \times (n_s+n_u)}
\end{equation}

\begin{equation}
    \bm{D}_{p_k}=\frac{\partial \bm{\gamma}_k}{\partial \bm{z}_k}= 
    \begin{bmatrix}
     \frac{\partial \bm{\gamma}_k}{\partial \bm{x}_k} & \frac{\partial \bm{\gamma}_k}{\partial \bm{u}_k} 
    \end{bmatrix} \in \real^{p \times (n_s+n_u)}
\end{equation}

\begin{equation}
    \bm{D}_{t_0}=\frac{\partial \bm{e}}{\partial t_0}  \in \real^{n_e}
\end{equation}

\begin{equation}
    \bm{D}_{t_F}=\frac{\partial \bm{e}}{\partial t_F}  \in \real^{n_e}
\end{equation}

\begin{equation}
    \bm{D}_{e_0}=\frac{\partial \bm{e}}{\partial \bm{z}_0}= 
    \begin{bmatrix}
     \frac{\partial \bm{e}}{\partial \bm{x}_0} & \frac{\partial \bm{e}}{\partial \bm{u}_0} 
    \end{bmatrix} \in \real^{n_e \times (n_s+n_u)}
\end{equation}

\begin{equation}
    \bm{D}_{e_N}=\frac{\partial \bm{e}}{\partial \bm{z}_N}= 
    \begin{bmatrix}
     \frac{\partial \bm{e}}{\partial \bm{x}_N} & \frac{\partial \bm{e}}{\partial \bm{u}_N} 
    \end{bmatrix} \in \real^{n_e \times (n_s+n_u)}
\end{equation}

\subsection{Sparsity detection of the Derivative Matrix using the propagation algorithm}

Unlike the constant matrices $\bm{A}$ and $\bm{B}$ the sparsity pattern of the Derivative Matrix not only depends on the dimensions of the problem but also of the structure of the dynamics, path constraints and event constraints of the problem. To apply the propagation algorithm for the computation of this sparsity pattern the following methodology is propose:

\begin{enumerate}
    \item Set the constant values of the Derivative matrix ($I_{n_s \times 2}$) into the triplet.
    \item Compute the sparsity template of the $D_{f_k}$ and $D_{p_k}$ matrices.
    \item Propagate the sparsity templates.
    \item Compute the sparsity templates of the events constrains ($\bm{D}_{t_0},\bm{D}_{t_F},\bm{D}_{e_0},\bm{D}_{e_N}$).
    \item Insert the sparsity templates of the event constraints in to the triplet.
\end{enumerate}

\subsubsection{Constant values of the Derivative Matrix}

Following the structure of (\ref{mat:D_structure}) it is easy to notice that some elements remain constant independently of the structure of the system and its constraints (Varying only with the dimensions of the problem). In particular, the first two columns of the matrix follow this pattern along the propagation of the derivatives of the dynamics ($\bm{D}_{f_k}$) and at the end of the matrix for the time constraint (This constraint may be deprecated). The sparsity pattern can be described as:

\begin{table}[h]
\begin{center}
\begin{tabular}{c|c|c}
Row    & Column        & Value \\ \hline
$0$      & $0$             & 1    \\
$1$    & $0$           & 1    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
$(n_s)(n_{colPoints})-1$ & $0$        & 1    \\
$0$      & $1$             & 1    \\
$1$    & $1$           & 1    \\
$\vdots$ & $\vdots$   &    $\vdots$     \\
$(n_s)(n_{colPoints})-1$ & $1$        & 1 \\
$(n_{colPoints})(n_s+p)+n_e$ & $0$ &$1$\\
$(n_{colPoints})(n_s+p)+n_e$ & $1$ &$1$\\
\end{tabular}
\end{center}
\end{table}

\newpage
\subsubsection{The derivative of the dynamics and its propagation}

Let us propose a generalized sparsity template for $D_{f_k}$

\begin{table}[h]
\begin{center}
\begin{tabular}{c|c|c}
Row                 & Column            \\ \hline
$\alpha_1$          & $\Omega_1$         \\
$\alpha_2$          & $\Omega_2$         \\
$\vdots$            & $\vdots$          \\
$\alpha_{f_{nz}}$   & $\Omega_{f_{nz}}$  \\
\end{tabular}
\end{center}
\end{table}

\noindent where $f_{nz}$ is the number of non-zero elements on $D_{f_k}$.\\

\noindent Using the structure of the derivative matrix, the following generalized template can be proposed for the propagation of $D_{f_k}$

\begin{table}[h]
\begin{center}
\begin{tabular}{c|c|c}
Row                 & Column            \\ \hline
$\alpha_1+(k)(n_s)$          & $\Omega_1+(k)(n_s+n_u)+2$         \\
$\alpha_2+(k)(n_s)$          & $\Omega_2+(k)(n_s+n_u)+2$         \\
$\vdots$            & $\vdots$          \\
$\alpha_{f_{nz}}+(k)(n_s)$   & $\Omega_{f_{nz}}+(k)(n_s+n_u)+2$  \\
\end{tabular}
\end{center}
\end{table}

\noindent for $k=0...(n_{colPoints}-1)$

\subsubsection{The derivative of the path constraints and its propagation}

Let us propose a generalized sparsity template for $D_{p_k}$

\begin{table}[h]
\begin{center}
\begin{tabular}{c|c|c}
Row                 & Column            \\ \hline
$\mu_1$          & $\Phi_1$         \\
$\mu_2$          & $\Phi_2$         \\
$\vdots$            & $\vdots$          \\
$\mu_{p_{nz}}$   & $\Phi_{p_{nz}}$  \\
\end{tabular}
\end{center}
\end{table}

\noindent where $p_{nz}$ is the number of non-zero elements on $D_{p_k}$.\\

\noindent Using the structure of the derivative matrix, the following generalized template can be proposed for the propagation of $D_{p_k}$

\begin{table}[!h]
\begin{center}
\begin{tabular}{c|c|c}
Row                 & Column            \\ \hline
$\mu_1+(k)(n_p)+p_{offset}$          & $\Phi_1+(k)(n_s+n_u)+2$         \\
$\mu_2+(k)(n_p)+p_{offset}$          & $\Phi_2+(k)(n_s+n_u)+2$         \\
$\vdots$            & $\vdots$          \\
$\mu_{p_{nz}}+(k)(n_p)+p_{offset}$   & $\Phi_{p_{nz}}+(k)(n_s+n_u)+2$  \\
\end{tabular}
\end{center}
\end{table}

\noindent where $p_{offset}=(n_{colPoints})(n_s)+n_e$ and for $k=0...(n_{colPoints}-1)$

\subsubsection{The derivative of the event constraints}

The event constraints not need any propagation through the derivative matrix, instead the insertion of the elements into the triplet is enough to define its sparsity.

Let us propose a generalized sparsity template for $D_{t_0}$ and $D_{t_F}$ 

\begin{table}[h]
\begin{center}
\begin{tabular}{c|c|c}
Row                 & Column            \\ \hline
$\varepsilon^0_1$          & $0$         \\
$\varepsilon^0_2$          & $0$         \\
$\vdots$            & $\vdots$          \\
$\varepsilon^0_{t_{nz_0}}$   & $0$  \\
\end{tabular}
\end{center}
\end{table}
\begin{table}[h]
\begin{center}
\begin{tabular}{c|c|c}
Row                 & Column            \\ \hline
$\varepsilon^F_1$          & $1$         \\
$\varepsilon^F_2$          & $1$         \\
$\vdots$            & $\vdots$          \\
$\varepsilon^F_{t_{nz_F}}$   & $1$  \\
\end{tabular}
\end{center}
\end{table}

\noindent where $t_{nz_0}$ is the number of non-zero elements on $D_{t_0}$ and $t_{nz_F}$ is the number of non-zero elements on $D_{t_F}$.\\

\noindent Using the structure of the derivative matrix, the following generalized template can be proposed for the insertion of $D_{t_0}$ and $D_{t_F}$: 

\begin{table}[!h]
\begin{center}
\begin{tabular}{c|c|c}
Row                 & Column            \\ \hline
$\varepsilon^0_1+e_{offset}$          & $0$         \\
$\varepsilon^0_2+e_{offset}$         & $0$         \\
$\vdots$            & $\vdots$          \\
$\varepsilon^0_{t_{nz_0}}+e_{offset}$   & $0$  \\
$\varepsilon^F_1+e_{offset}$          & $1$         \\
$\varepsilon^F_2+e_{offset}$         & $1$         \\
$\vdots$            & $\vdots$          \\
$\varepsilon^F_{t_{nz_F}}+e_{offset}$   & $1$  \\
\end{tabular}
\end{center}
\end{table}

\noindent where $e_{offset}=(n_{colPoints})(n_s)$.\\
\newpage
\noindent Following the same procedure, the proposed generalized template of $D_{e_0}$ :

\begin{table}[!h]
\begin{center}
\begin{tabular}{c|c|c}
Row             & Column            \\ \hline
$i_1$           & $j_1$         \\
$i_2$           & $j_2$         \\
$\vdots$        & $\vdots$          \\
$i_{e_{nz_0}}$  & $j_{e_{nz_0}}$  \\
\end{tabular}
\end{center}
\end{table}

\noindent and $D_{e_N}$:

\begin{table}[!h]
\begin{center}
\begin{tabular}{c|c|c}
Row             & Column            \\ \hline
$a_1$           & $b_1$         \\
$a_2$           & $b_2$         \\
$\vdots$        & $\vdots$          \\
$a_{e_{nz_N}}$  & $b_{e_{nz_N}}$  \\
\end{tabular}
\end{center}
\end{table}

\noindent where $e_{nz_0}$ is the number of non-zero elements on $D_{e_0}$ and $e_{nz_N}$ is the number of non-zero elements on $D_{e_N}$.\\

\noindent The following generalized template can be proposed for the insertion of $D_{e_0}$ and $D_{e_N}$: 

\begin{table}[!h]
\begin{center}
\begin{tabular}{c|c|c}
Row             & Column            \\ \hline
$i_1+e_{offset}$           & $j_1+2$         \\
$i_2+e_{offset}$           & $j_2+2$         \\
$\vdots$        & $\vdots$          \\
$i_{e_{nz_0}}+e_{offset}$  & $j_{e_{nz_0}}+2$  \\
$a_1+e_{offset}$           & $n_{decVar}-(n_s+n_u)+b_1$         \\
$a_2+e_{offset}$           & $n_{decVar}-(n_s+n_u)+b_2$         \\
$\vdots$        & $\vdots$          \\
$a_{e_{nz_N}}+e_{offset}$  & $n_{decVar}-(n_s+n_u)+b_{e_{nz_N}}$  \\
\end{tabular}
\end{center}
\end{table}

\subsubsection{Computing the derivative matrix sparsity}

The total number of non-zero on $\bm{D}$ can be computed as:

\begin{equation*}
    \bm{D}_{nz}=(f_{nz}+p_{nz}+2n_s)(n_{colPoints})+ t_{nz_0} + t_{nz_F} + e_{nz_0}+ e_{nz_N}+2
\end{equation*}

\newpage

\begin{algorithm}[h!]
	\caption{Sparsity detection of D using propagation algorithm} 
	\begin{algorithmic}[1]
	    \State $p_{offset}=(n_{colPoints})(n_s)+n_e$
	    \State $e_{offset}=(n_{colPoints})(n_s)$
	    \For {$k=0,1, \ldots, (n_s)(n_{colPoints})-1$}
	        \State $iRow=k$
	        \State $iCol=0$
	        \State Save the information in the triplet ($iRow$, $iCol$, 1)
	        \State $iCol=1$
	        \State Save the information in the triplet ($iRow$, $iCol$, 1)
	    \EndFor
	    %
		\For {$k=0,1,\ldots,(n_{colPoints}-1)$}
			\For {$d=0,1,\ldots,f_{nz}$}
			    \State $iRow=\alpha_d+(k)(n_s)$
			    \State $iCol=\Omega_d+(k)(n_s+n_u)+2$
				\State Save the information in the triplet ($iRow$, $iCol$, 1)
			\EndFor
			\For {$d=0,1,\ldots,p_{nz}$}
			    \State $iRow=\mu_d+(k)(p)+p_{offset}$
			    \State $iCol=\Phi_d+(k)(n_s+n_u)+2$
				\State Save the information in the triplet ($iRow$, $iCol$, 1)
			\EndFor
		\EndFor
		\For {$d=0,1,\ldots,t_{nz_0}$}
		        \State $iRow=\varepsilon^0_d+ e_{offset}$
			    \State $iCol=0$
				\State Save the information in the triplet ($iRow$, $iCol$, $1$)
		\EndFor
		\For {$d=0,1,\ldots,t_{nz_F}$}
		        \State $iRow=\varepsilon^F_d+ e_{offset}$
			    \State $iCol=1$
				\State Save the information in the triplet ($iRow$, $iCol$, $1$)
		\EndFor
		\For {$d=0,1,\ldots,e_{nz_0}$}
		        \State $iRow=i_d+ e_{offset}$
			    \State $iCol=j_d+2$
				\State Save the information in the triplet ($iRow$, $iCol$, $1$)
		\EndFor
		\For {$d=0,1,\ldots,e_{nz_N}$}
		        \State $iRow=a_d+ e_{offset}$
			    \State $iCol=n_{decVar}-(n_s+n_u)+b_d$
				\State Save the information in the triplet ($iRow$, $iCol$, $1$)
		\EndFor		
		
	\end{algorithmic} 
\end{algorithm}

\newpage

\subsection{Computing the Derivative Matrix using the propagation algorithm}

Let us propose the following Derivative Matrix $D$

\begin{equation} \label{mat:D_computation}
\bm{D}=\begin{bmatrix}
\frac{\partial \Delta t \bm{f}_0}{\partial t_0} & \frac{\partial \Delta t \bm{f}_0}{\partial t_F} & \bm{D}_{f_0} &  &  & \\ 
\frac{\partial \Delta t \bm{f}_1}{\partial t_0} & \frac{\partial  \Delta t\bm{f}_1}{\partial t_F} & \bm{0} & \bm{D}_{f_1} &  & \\ 
\vdots  & \vdots  & \vdots & & \ddots& \\ 
\frac{\partial \Delta t \bm{f}_N}{\partial \bm{t}_0} & \frac{\partial \Delta t \bm{f}_N}{\partial \bm{t}_F} & \bm{0} & \bm{0} & \hdots & \bm{D}_{f_N}\\ 
\bm{D}_{t_0} & \bm{D}_{t_F} &  \bm{D}_{e_0}& \bm{0} & \hdots &\bm{D}_{e_N} \\ 
\bm{0} & \bm{0} & \bm{D}_{p_0} & \bm{0} &  & \\ 
\bm{0} & \bm{0} & \bm{0} &\bm{D}_{p_1}  &  & \\ 
\vdots& \vdots  &  & &  \ddots& \\ 
 \bm{0}& \bm{0} &  & &  &\bm{D}_{p_N} \\ 
 1&1 & 0 & 0 & \hdots & 0 
\end{bmatrix}
\end{equation}

\noindent where

\begin{equation}
    \bm{D}_{f_k}=\Delta t 
    \begin{bmatrix}
     \frac{\partial \bm{f}_k}{\partial \bm{x}_k} & \frac{\partial \bm{f}_k}{\partial \bm{u}_k} 
    \end{bmatrix} \in \real^{n_s \times (n_s+n_u)}
\end{equation}

\begin{equation}
    \bm{D}_{p_k}= 
    \begin{bmatrix}
     \frac{\partial \bm{\gamma}_k}{\partial \bm{x}_k} & \frac{\partial \bm{\gamma}_k}{\partial \bm{u}_k} 
    \end{bmatrix} \in \real^{p \times (n_s+n_u)}
\end{equation}

\begin{equation}
    \bm{D}_{t_0}=\frac{\partial \bm{e}}{\partial t_0}  \in \real^{n_e}
\end{equation}

\begin{equation}
    \bm{D}_{t_F}=\frac{\partial \bm{e}}{\partial t_F}  \in \real^{n_e}
\end{equation}

\begin{equation}
    \bm{D}_{e_0}= 
    \begin{bmatrix}
     \frac{\partial \bm{e}}{\partial \bm{x}_0} & \frac{\partial \bm{e}}{\partial \bm{u}_0} 
    \end{bmatrix} \in \real^{n_e \times (n_s+n_u)}
\end{equation}

\begin{equation}
    \bm{D}_{e_N}= 
    \begin{bmatrix}
     \frac{\partial \bm{e}}{\partial \bm{x}_N} & \frac{\partial \bm{e}}{\partial \bm{u}_N} 
    \end{bmatrix} \in \real^{n_e \times (n_s+n_u)}
\end{equation}

\begin{equation}
    \frac{\partial \Delta t \bm{f}_k}{\partial t_0}=-\bm{f}_k \in \real^{n_s}
\end{equation}

\begin{equation}
    \frac{\partial \Delta t \bm{f}_k}{\partial t_F}=\bm{f}_k \in \real^{n_s}
\end{equation}

Exploiting the propagation algorithm applied in the sparsity detection of the derivative matrix is possible to propose the following algorithm to compute the value of the derivative matrix

\begin{algorithm}
	\caption{Computation of the Derivative Matrix} 
	\begin{algorithmic}[1]
	    \State $p_{offset}=(n_{colPoints})(n_s)+n_e$
	    \State $e_{offset}=(n_{colPoints})(n_s)$
	    \State $h_k=t_F-t_0$
	    %
		\For {$k=0,1,\ldots,(n_{colPoints}-1)$}
		    %
		    \State Compute the dynamics $\bm{f}_k$
		    \State Compute $\bm{D}_{f_k}$ and $\bm{D}_{p_k}$
			\For {$d=kn_s,kn_s+1,\ldots,kn_s+n_s$}
			    \State $iRow=d$
			    \State $iCol=0$
			    \State $f_d= $ The $d$ element of the $\bm{f}_k$ vector
				\State Save the information in the triplet ($iRow$, $iCol$, $-f_d$)
			\EndFor
			%
			\For {$d=0,1,\ldots,f_{nz}$}
			    \State $iRow=\alpha_d+(k)(n_s)$
			    \State $iCol=\Omega_d+(k)(n_s+n_u)+2$
			    \State $d_{f_k}=$The element of $ \bm{D}_{f_k} $ at $ (\alpha_d,\Omega_d)$
				\State Save the information in the triplet ($iRow$, $iCol$, $h_kd_{f_k}$)
			\EndFor
			%
			\For {$d=0,1,\ldots,p_{nz}$}
			    \State $iRow=\mu_d+(k)(p)+p_{offset}$
			    \State $iCol=\Phi_d+(k)(n_s+n_u)+2$
			    \State $d_{p_k}=$The element of $ \bm{D}_{p_k} $ at $ (\mu_d,\Phi_d)$
				\State Save the information in the triplet ($iRow$, $iCol$, $d_{p_k}$)
			\EndFor
		\EndFor
		\State Compute $\bm{D}_{t_0}$, $\bm{D}_{t_F}$, $\bm{D}_{e_0}$ , $\bm{D}_{e_N}$
		\For {$d=0,1,\ldots,t_{nz_0}$}
		        \State $iRow=\varepsilon^0_d+ e_{offset}$
                \State $d_{t_0}=$ The element of $\bm{D}_{t_0}$ at $\varepsilon^0_d$
				\State Save the information in the triplet ($iRow$, $0$, $d_{t_0}$)
		\EndFor
		\For {$d=0,1,\ldots,t_{nz_F}$}
		        \State $iRow=\varepsilon^F_d+ e_{offset}$
                \State $d_{t_F}=$ The element of $\bm{D}_{t_F}$ at $\varepsilon^F_d$
				\State Save the information in the triplet ($iRow$, $1$, $d_{t_F}$)
		\EndFor
		\For {$d=0,1,\ldots,e_{nz_0}$}
		        \State $iRow=i_d+ e_{offset}$
			    \State $iCol=j_d+2$
			    \State $d_{e_0}=$ The element of $\bm{D}_{e_0}$ at $(i_d,j_d)$
				\State Save the information in the triplet ($iRow$, $iCol$, $d_{e_0}$)
		\EndFor
		\For {$d=0,1,\ldots,e_{nz_N}$}
		        \State $iRow=a_d+ e_{offset}$
			    \State $iCol=n_{decVar}-(n_s+n_u)+b_d$
			    \State $d_{e_N}=$ The element of $\bm{D}_{e_N}$ at $(a_d,b_d)$
				\State Save the information in the triplet ($iRow$, $iCol$, $d_{e_N}$)
		\EndFor		
		
	\end{algorithmic} 
\end{algorithm}


\end{document}

